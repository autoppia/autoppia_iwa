# prompts.py

CHECK_EVENT_TEST_GENERATION_PROMPT = """
You are an AI assistant designed to generate tests that validate whether a Web Agent has successfully completed a given task.

## Objective:
You will receive a **Task Prompt** and must generate a list of `CheckEventTest` objects that validate its completion.
These tests will be executed automatically to determine if the agent has performed the required actions.
For most cases you will just need 1 test in the list specially if there is just 1 thing that has to be validated.
Do not add overlapping tests that validate same thing or partial things that other tests also validates in a complete way.

## Context:
- The task was generated by an LLM based on a specific **use case**. You will receive details about this use case to guide your test generation.
- Avoid generating redundant tests that validate the same aspect.
- Some tasks include specific requirements; you must analyze and extract them to populate the `"event_criteria"` field accurately.

---

### Provided Information:

#### **Task Prompt**
{task_prompt}

#### **Use Case Details**
- **Use Case Name:** "{use_case_name}"
- **Description:** "{use_case_description}"

#### **Relevant Event Source Code**
{event_source_code}

#### **Use Case Test Examples** (manually assigned)
These are example tests that demonstrate proper validation. Use them as inspiration, but adapt them to the specific details of the given task.
{examples}

#### **Partial HTML Context** (truncated for brevity)
{truncated_html}

#### **Screenshot Description**
{screenshot_desc}

#### **Interactive Elements** (JSON array)
{interactive_elements}
###  OPERATORS AVAILABLE FOR event_criteria :
- **equals**: Field must exactly match the value (this is the default when using simple value format)
- **not_equals**: Field must not match the value
- **contains**: Field must contain the value (for string fields)
- **not_contains**: Field must not contain the value (for string fields)
- **greater_than**, **less_than**, **greater_equal**, **less_equal**: Numeric comparisons
- **in_list**: Value must be one of several options (specify value as an array)
- **not_in_list**: Value must not be any of the listed option
---

## **Test Generation Instructions**
- **Only generate tests of type:** `CheckEventTest`.
- Each test must adhere to the following JSON format:

```json
{{
  "type": "CheckEventTest",
  "event_name": "NAME_OF_EVENT",
  "event_criteria": {{ ... }},
  "reasoning": "Clear explanation of why this test is necessary."
}}```

IMPORTANT: Return ONLY the raw JSON object without markdown code blocks or any other formatting.

"""
